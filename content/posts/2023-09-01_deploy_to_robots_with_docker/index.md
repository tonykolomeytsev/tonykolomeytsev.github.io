+++
title = "Опыт Eurobot: Деплой Docker образов на роботов в локальной сети"
date = "2023-09-01"
draft = true

[taxonomies]
tags = ["docker", "ROS", "robotics", "eurobot", "skoltech", "guide"]
+++

Продолжая серию постов про Eurobot, рассказываю про следующую деталь нашей инфраструктуры — доставку Docker образов до роботов в обход интернета и удаленных Docker Registry.

[В предыдущем посте](/posts/eurobot-experience-docker-with-ros/) я рассказал о том, как мы собирали Docker образы и как контейнеры запускались на роботах. В этот раз расскажу, как эти самые образы по Wi-Fi доставлялись с машин разработчиков на роботов.

Для опытных бэкендеров скорее всего материал поста не будет новым. Для меня же большая часть описанного здесь в свое время стала откровением.

<center>

![Deploying Docker App](deploying-app.jpg)

*Именно так выглядит деплой*

</center>

# Мотивация

Во время подготовки к соревнованиям мы использовали как классический подход доставки образов, через Docker Hub, так и эзотерический — по локальной сети. 

Первый способ мы использовали в основном, загружая в Docker Hub стабильные образы, собранные из ветки master на CI в нашем репозитории. Мы точно знали что в публичном репозитории находятся рабочие образы и иногда откатывались к ним.

По локальной сети же мы деплоили в 99% случаев, находясь физически в лабе и отлаживая роботов вечерами после пар.

Таким образом, заливать образы минуя интернет мы хотели по двум причинам: 
1. Это тупо быстрее и удобнее.
1. На соревнованиях, куда мы приедем, может не быть интернета или он может быть нестабилен.

# Самое простое решение
<!-- Тут рассказать про первое решение до которого я додумался, экспорт docker образа в tar архив и его отправка -->

Первое решение, которое мне пришло в голову, [пришло в голову кому-то еще до меня](https://stackoverflow.com/questions/23935141/how-to-copy-docker-images-from-one-host-to-another-without-using-a-repository). Заключалось решение в следующем:

1. Собираем Docker образ.
2. Экспортируем образ в tar архив.
3. Отправляем tar архив при помощи `rsync` или `scp` на робота.
4. На роботе импортируем tar архив обратно в образ.

Решение железное и супер понятное, но во всем остальном оно ужасно:

- Вы тратите время не только на сборку образа, но и на его экспорт. Экспорт ROS образов у нас занимал 20-30 секунд.
- Нельзя отправить только изменившиеся слои образа, придется каждый раз отправлять ВЕСЬ образ.
- Образы с ROS весят больше гигабайта, и даже архивирование их не спасает. Передача таких тяжелых образов сама по себе будет съедать пару минут времени (я проверял).

Я реализовал этот способ, понял что он работает ужасно долго и для нас он не подходит. Поэтому тратить буквы на него не буду, сразу перейду к объяснению финального решения.

# Самое сложное решение
<!-- Тут рассказать сразу про суть текущего решения -->

Оптимальное решение работает следующим образом:

1. Собираем образ локально на своем лэптопе/ПК/микроволновке.
2. Поднимаем на роботе Docker Registry, через SSH конечно.
3. Поднимаем SSH туннель между вашей машиной и роботом.
4. Пушим собранный вами локально образ в Docker Registry, расположенный на роботе.
5. Чистим за собой: SSH тоннель и Docker Registry.

Зачем нужен Docker Registry? Зачем SSH тоннель? Почему мы не выключаем Registry после загрузки?

На все эти вопросы по ходу отвечу.

## Шаг 0: Предварительная настройка
### Настраиваем SSH-ключи
<!-- Про SSH ключи и почему они нужны -->

> Я настоятельно рекомендую один раз выполнить этот пункт, в противном случае работоспособность кода ниже уже будет под вопросом, а удобство использования гарантированно пострадает.

SSH-ключи, это более безопасная альтернатива паре логин/пароль, позволяющая один раз "зарегистрировать" ваш лэптоп в пямяти робота и далее входить с того же устройства уже без явной авторизации. Нормальное объяснение SSH-ключей: [ТЫК](https://selectel.ru/blog/ssh-keys/).

#### Проверяем что ключ уже есть

Проверить, что у вас уже есть SSH-ключ на устройстве, можно при помощи команды ниже. Если в списке файлов будут `id_rsa` и `id_rsa.pub`, новый ключ генерировать не нужно:

```bash
ls ~/.ssh/
```

#### Генерируем SSH-ключ

Если у вас еще нет SSH ключа на устройстве, нужно [выпустить новый](https://selectel.ru/blog/tutorials/how-to-generate-ssh/). Команда для выпуска ключа следующая:

```bash
ssh-keygen -t rsa
```

Пароль для SSH-ключа ставить не надо. После генерации у вас появится два файла в директории `~/.ssh/`: `id_rsa` - приватный ключ, `id_rsa.pub` - публичный ключ.

#### Регистрируем SSH-ключ на роботе

В команде ниже:
- `user` - имя юзера в ОС робота. У нас в RESET имя юзера всегда было `nuc`.
- `host` - IP-адрес робота в локальной сети. IP адресу лучше быть статическим, либо у робота должен быть домен в локальной сети, например `robot.local`.

```bash
ssh-copy-id user@host
```

### Docker BuildKit
<!-- Про то как настроить BuildKit и разрешить пушить в localhost:5000 -->

BuildKit это новый бэкенд для Docker, который нам нужен конкретно из-за своей способности билдить образы под разные архитектуры процессоров.

Убедитесь что на вашем компе установлен один из трех вариантов софта с BuildKit внутри:
- Docker Desktop — рекомендую ставить именно его и не париться.
- Docker версии 23.0 и выше.
- Старая версия Docker с [установленным BuildKit](https://docs.docker.com/build/buildkit/) — хз зачем вам вообще может понадобится эта опция, ~~только если вы 50-летний пердун из Яндекса/МэйлРу~~.

### Установка BuildKit Builder и настройка Insecure Registry

> TODO: ССЫЛКУ ХОТЬ ДАЙ НА БИЛДЕР ЧТОБ ПОЧИТАТЬ И ПОНЯЬ ЧТО ЭТО

До первого билда нужно создать **builder** — контейнер с эмулятором для билда под разные архитектуры. У нас, например, вызывался вот такой код:

```bash
docker buildx create \
    --name eurobot-builder \
    --config buildkitd.default.toml \
    --bootstrap --use
```

Опция `--bootstrap` сразу запустит билдер, опция `--use` сделает его билдером по-умолчанию.

Заводить свой билдер нужно из-за того, что из коробки Docker не позволяет отправлять образы куда-либо, кроме защищенных цифровой подписью репозиториев в интернетах. Нам нужно разрешить пушить образы по адресу `http://localhost:5000` и делаем мы это в файле `buildkitd.default.toml`:

```toml
[registry."host.docker.internal:5000"]
http = true
```

BuildKit использует Docker контейнер с эмулятором чтобы билдить ваши Docker образы. Эмулятору недоступна ваша локальная сеть, по адресу `localhost` он будет получать доступ ко внутренней сети Docker. Чтобы обойти эту проблему, в Docker есть специальный алиас `host.docker.internal`, ведущий в "настоящую" локальную сеть вашего компьютера. Про алиас и конкретно наш юзкейс можно почитать подробнее в [документации Docker](https://docs.docker.com/desktop/networking/#i-want-to-connect-from-a-container-to-a-service-on-the-host).

## Шаг 1: Собираем образ локально {#step-1}
<!-- Рассказать про нюансы локальной сборки, которые есть при использовании данного метода деплоя -->

Из корня проекта нашего проекта запускается примерно вот такой код:

```bash
docker buildx build \
    --platform $PLATFORM \
    --tag eurobot2023:$WS_NAME \
    --output type=image,push=false \
    --file $WS_NAME/Dockerfile \
    .
```

Разберем по порядку:

1. Запускаем билд с помощью `docker buildx build` — явно сообщаем Docker чтобы он использовал BuildKit.
1. Опция `--platform` определяет, [под какую архитектуру будет сбилжен образ](https://docs.docker.com/engine/reference/commandline/buildx_build/#platform). Например:
    * Intel NUC это `linux/amd64`, 
    * Raspberry Pi 3B+ это `linux/arm/v7`, 
    * Raspberry Pi 4 и Nvidia Jetson Nano это `linux/arm64`.
1. Опция `--tag` определяет имя образа. Про `$WS_NAME` рассказано ниже.
1. Опция `--output` позволяет указать, [что делать с результатом билда](https://docs.docker.com/engine/reference/commandline/buildx_build/#output). В нашем случае это `type=image,push=false` — собираем OCI образ, никуда не пушим, в Docker не экспортируем:
    * Не тратится время на экспорт образов в Docker. Билд происходит быстрее.
    * Сбилженные образы хранятся в кэше, их не видно в приложении Docker Desktop или при вызове `docker images`. Таким образом частый билд не засирает вам список ваших образов.
1. Опцией `--file` указывался `Dockerfile` из нужного воркспейса.
1. В переменной `$WS_NAME` имя воркспейса, который сейчас собираются билдить. Подробно про "воркспейсы" и структуру нашего проекта я рассказывал в [предыдущем посте](/posts/eurobot-experience-docker-with-ros/).

## Шаг 2: Поднимаем Docker Registry на роботе
<!-- Объяснить, почему insecure registry на самом деле secure благодаря SSH -->

Docker Registry поднятый на роботе сам определяет, какие слои сбилженного обрза изменились и запрашивает только изменившиеся. Нам нужно только подключиться к этому Registry, остальное будет сделано за нас.

Я использовал примерно вот такой код, для того чтобы через SSH запустить на роботе Registry:

```bash
ssh -o ConnectTimeout=5 \
    -o StrictHostKeyChecking=no \
    -o UserKnownHostsFile=/dev/null \
    $ROBOT_HOSTNAME "
        docker run -d \
            -v /etc/docker-push-ssh/registry:/var/lib/registry \
            --name registry \
            --restart always \
            -p 127.0.0.1:5000:5000 \
            registry:2 || true
    "
```

Разбираем по порядку:
1. Подключаемся по SSH к `$ROBOT_HOSTNAME`. Это как раз `user@host` из пункта про SSH-ключи — например `nuc@192.168.1.64`.
1. Опцию `-o ConnectTimeout=5` вы и сами сможете нагуглить. 
1. Опции `-o StrictHostKeyChecking=no` и `-o UserKnownHostsFile=/dev/null` нужны для [автоматического принятия RSA ключей](https://wiki.enchtex.info/practice/ssh_accept_host_key) клиентом SSH. Это сделано для удобства, чтобы вас никто не спрашивал "ДЕЙСТВИТЕЛЬНО ХОТИТЕ ПОДКЛЮЧИТЬСЯ?" и для того чтобы у вас не разрастался файл `known_hosts` при смене IP адресов роботов.
1. После установки соединения выполняем команду:
    ```bash
    docker run -d \
        -v /etc/docker-push-ssh/registry:/var/lib/registry \
        --name registry \
        --restart always \
        -p 127.0.0.1:5000:5000 \
        registry:2 || true
    ```
    Да, мы просто запускаем на роботе контейнер с Docker Registry. По-умолчанию Registry работает на порте 5000, при помощи биндинга `-p 127.0.0.1:5000:5000` мы делаем его доступным [только в локальной сети](https://brokkr.net/2022/03/29/publishing-docker-ports-to-127-0-0-1-instead-of-0-0-0-0/). 
    
    > Образ с Registry весит в районе 20 мегабайт и в режиме бездействия не потребляет фактически никаких ресурсов. Так что если он будет все время работать, ничего плохого не произойдет даже на слабых компах типа Raspberry 3B+. Вместо `|| true` можно придумать более элегантное решение.

## Шаг 3: Поднимаем SSH туннель между роботом и компьютером

Снова используем утилиту SSH:

```bash
ssh -N \
    -o StrictHostKeyChecking=no \
    -o UserKnownHostsFile=/dev/null \
    -L *:5000:localhost:5000 \
    $ROBOT_HOSTNAME \
    & echo $! > SSHPID
```

Разбираем что происходит:
1. Подключаемся по SSH к `$ROBOT_HOSTNAME` (к `user@host`).
1. Опция `-N` позволяет не запускать никакую команду.
1. Опция `-L *:5000:localhost:5000` пробрасывает порты из сети нашего компьютера в локальную сеть робота. Это "тот самый" SSH туннель из начала поста. Таким образом нам будет доступен Docker Registry, запущенный в локальной сети на роботе.
1. Сам запуск ssh блокирует терминал, поэтому используем `&` чтобы запустить процесс в фоне и сразу записываем ID процесса в файл `SSHPID` для того чтобы закрыть тоннель после деплоя.

> В команде RESET до последнего момента SSH туннель запускался немного иначе — в виде Docker контейнера с утилитой ssh внутри. Это негативно сказывалось на скорости установки и сброса соединения, но зато было удобно выключать процесс, просто останавливая Docker контейнер. Но настраивать такую конфигурацию сложнее.

### Бонус: дожидаемся запуска SSH-туннеля

В Unix-системах скрипт ниже будет дожидаться, когда станет доступен Docker Registry:

```bash
#!/bin/bash

for i in {1..15}; do
    echo "Waiting for SSH Tunnel Initialization... "
    sleep 1
    curl -Is http://localhost:5000/v2/ &>/dev/null && break
    if ((i == 15)); then
        echo "Establishing SSH Tunnel timeout" &>$LOGS_DIR/subtask.log
        exit_clearly 2
    fi
done
```

Что выведет curl в случае успешного поднятия туннеля:

```
HTTP/1.1 200 OK
Content-Length: 2
Content-Type: application/json; charset=utf-8
Docker-Distribution-Api-Version: registry/2.0
X-Content-Type-Options: nosniff
Date: Mon, 04 Sep 2023 20:02:21 GMT
```

У нас использовался именно этот скрипт, который "пингует" `localhost:5000`. Его недостаток в том что на Windows он не заработает. Можно переписать на Python, тогда будет работать на всех платформах.

## Шаг 4: Пушим образ в Docker Registry на роботе

Для этого используем ту же самую команду, что и для билда, но с двумя модификациями: 
1. `--output type=registry`.
2. `--tag host.docker.internal:5000/eurobot2023:$WS_NAME`.

```bash 
docker buildx build \
    --platform $PLATFORM \
    --tag host.docker.internal:5000/eurobot2023:$WS_NAME \
    --output type=registry
    --file $WS_NAME/Dockerfile \
    .
```

Так как с момента предыдущего билда в [**Шаге 1**](#step-1) ничего не изменилось и все слои из докерфайла уже есть в кэше, стадия билда будет пропущена. Начнется загрузка образа в Docker Registry робота. Сам Registry так устроен, что будет принимать только те слои образа, которые изменились или которых не хватает.

Почему это вообще работает:
1. Опция `--output type=registry` указывает пушить в Registry после сборки образа.
2. В тег образа мы добавляем `host.docker.internal:5000` для того чтобы BuildKit билдер мог достучаться до Registry, который доступен из нашей локальной сети. Потому что `localhost` внутри контейнера с билдером ведет совсем в другое место)))

На самом роботе надо "стянуть" образ из Registry, чтобы он появился в списке при вызове `docker images` и после этого вернуть ему нормальное имя. Это мы тоже делаем через SSH:

```bash
ssh -o ConnectTimeout=5 \
    -o StrictHostKeyChecking=no \
    -o UserKnownHostsFile=/dev/null \
    $ROBOT_HOSTNAME "
        docker pull localhost:5000/eurobot2023:$WS_NAME && \
        docker tag localhost:5000/eurobot2023:$WS_NAME eurobot2023:$WS_NAME
    "
```

И на этом деплой закончился, образ `leurobot2023:$WS_NAME` уже на роботе и готов к запуску.

## Шаг 5: Чистим за собой

Чтобы остановить SSH-туннель, можно просто убить процесс ssh, id которого мы запомнили ранее:

```bash
cat SSHPID | xargs kill
rm SSHPID # не забываем удалить временный файл тоже
```

Останавливать Docker Registry на роботе, как я уже писал, смысла большого нет. Дешевле по времени и вычислительным ресурсам просто оставить его работать. Есть еще одна причина не трогать его — если вы работаете в команде и одновременно льете образы на робота, вы можете нечаянно завершить Registry пока кто-то другой передает образ. 

# Подводные камни

## Комментарий по поводу Mac OS

На Mac OS нельзя просто так взять и пробросить SSH-туннель для порта 5000. Все потому что служба AirPlay тоже использует этот порт. А еще Docker по-умолчанию использует порт 5000 для Registry. 

Забавная ситуация. Если хотите чтобы код заработал на вашем яблочном компьютере, [отключите службу AirPlay](https://habr.com/ru/news/591087/), либо поменяйте во всех скриптах из этого поста порт 5000 на другой, например на 5001.

## Расход места на диске

# Мы это автоматизировали

# Мои мысли на тему и итоги

# TODO:
- SSH в контейнере для того чтобы в Docker сети стал доступен localhost:5000, а не для удобства